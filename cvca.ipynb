{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhMldoPqiBM2"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1676484024626,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "LHcvwBFniBM3"
   },
   "outputs": [],
   "source": [
    "# Other modules are not supported during coursework marking.\n",
    "# Other modules cannot be used unless a written approval is given.\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# More information about skimage draw module can be found at \n",
    "# https://scikit-image.org/docs/stable/api/skimage.draw.html#skimage.draw.line\n",
    "from skimage.draw import line, line_aa\n",
    "from skimage.draw import circle_perimeter, circle_perimeter_aa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6TSQ0HaiBM4"
   },
   "source": [
    "---\n",
    "### Q1: Image negative\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1676484024910,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "Z1Uc9FoViBM5"
   },
   "outputs": [],
   "source": [
    "def my_image_negative(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function converts the input image into image negative.\n",
    "    The implementation is that output intensity = 255 - input intensity, where 255 is the maximum intensity of an 8-bit single channel image.\n",
    "    Then, output intensity is stored at the same pixel position.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "\n",
    "    Return: new_image = image negative.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined/built-in functions for image negative cannot be used.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the implementation does not follow the description above.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new imageko input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "    \n",
    "    for i in range(0,H-1):\n",
    "        for j in range(0,W-1):\n",
    "            pixel = input_image[i, j]\n",
    "            pixel=255-pixel\n",
    "            new_image[i, j] =pixel    \n",
    "\n",
    "    # This dummy code line can be removed after entering your code\n",
    "    #new_image = input_image.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT1qQMEpiBM6"
   },
   "source": [
    "---\n",
    "### Q2: Image smoothing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1676484024911,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "ulSWNZ1_iBM6"
   },
   "outputs": [],
   "source": [
    "def my_image_smoothing(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function smooths the input image by using a 3x3 mean filter.\n",
    "    The implementation of the 3x3 mean filter follows the details given in the Image Filtering lecture notes.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "    The input image is corrupted by random noise.\n",
    "\n",
    "    Return: new_image = filtered image.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the filter is not an average filter.\n",
    "    No mark if the implementation does not follow details given the lecture notes.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "    \n",
    "    result = 0\n",
    "    for j in range(1, H-1):\n",
    "        for i in range(1, W-1):\n",
    "            for y in range(-1, 2):\n",
    "                for x in range(-1, 2):\n",
    "                    result = result + input_image[j+y, i+x]\n",
    "            new_image[j][i] = int(result / 9)\n",
    "            result = 0\n",
    "\n",
    "    # This dummy code line can be removed after entering your code\n",
    "    #new_image = input_image.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msch6hdHiBM7"
   },
   "source": [
    "---\n",
    "### Q3: Edge gradient magnitude estimation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1676484024912,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "IPrDJ59OiBM8"
   },
   "outputs": [],
   "source": [
    "def my_grad_mag(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function estimates the edge gradient magnitude from the input image by using\n",
    "    the 3x3 Sobel operators along x and y directions.\n",
    "    The implementation of the 3x3 Sobel operators follows the details given in the Image Derivatives and Edge Detection lecture notes.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "    The input image is corrupted by random noise.\n",
    "\n",
    "    Return: new_image = filtered image.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for filtering, convolution, correlation, edge detection cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the filters are not Sobel filters.\n",
    "    No mark if the implementation does not follow details given the lecture notes.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "    \n",
    "    \n",
    "    # Here we define the matrices associated with the Sobel filter\n",
    "    Gx = np.array([[1.0, 0.0, -1.0], [2.0, 0.0, -2.0], [1.0, 0.0, -1.0]])\n",
    "    Gy = np.array([[1.0, 2.0, 1.0], [0.0, 0.0, 0.0], [-1.0, -2.0, -1.0]])\n",
    "    #[rows, columns] = np.shape(grayscale_image)  # we need to know the shape of the input grayscale image\n",
    "    #sobel_filtered_image = np.zeros(shape=(rows, columns))  # initialization of the output image array (all elements are 0)\n",
    "\n",
    "    # Now we \"sweep\" the image in both x and y directions and compute the output\n",
    "    for i in range(H - 2):\n",
    "        for j in range(W - 2):\n",
    "            gx = np.sum(np.multiply(Gx, input_image[i:i + 3, j:j + 3]))  # x direction\n",
    "            gy = np.sum(np.multiply(Gy, input_image[i:i + 3, j:j + 3]))  # y direction\n",
    "            new_image[i + 1, j + 1] = np.sqrt(gx ** 2 + gy ** 2)  # calculate the \"hypotenuse\"\n",
    "\n",
    "    # This dummy code line can be removed after entering your code\n",
    "    #new_image = input_image.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d4HgiU2iBM8"
   },
   "source": [
    "---\n",
    "### Q4: Image sharpening\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1676484024912,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "M_W9rQaCiBM9"
   },
   "outputs": [],
   "source": [
    "def my_image_sharpening(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function enhances the input image by using a 3x3 image sharpening filter.\n",
    "    The implementation of the 3x3 image sharpening filter follows the details given in the Image Filtering lecture notes.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "    The input image is corrupted by random noise.\n",
    "\n",
    "    Return: new_image = filtered image.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the filter is not an image sharpening filter.\n",
    "    No mark if the implementation does not follow details given the lecture notes.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "    \n",
    "    sharpen_filter = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    \n",
    "    for i in range(H - 2):\n",
    "        for j in range(W - 2):\n",
    "            gx = np.sum(np.multiply(sharpen_filter, input_image[i:i + 3, j:j + 3]))  # x direction\n",
    "            if gx > 255:\n",
    "                gx = 255\n",
    "            elif gx < 0:\n",
    "                gx = 0\n",
    "            new_image[i + 1, j + 1] = gx                   \n",
    "            \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1BFEBjyiBM9"
   },
   "source": [
    "---\n",
    "### Q5: Median filtering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1676484024913,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "IPJ4xHbMiBM-"
   },
   "outputs": [],
   "source": [
    "def my_median_filtering(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function enhances the input image by using a 3x3 median filter.\n",
    "    The implementation of the 3x3 median filter follows the details given in the Image Filtering lecture notes.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "    The input image is corrupted by random noise.\n",
    "\n",
    "    Return: new_image = filtered image.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the filter is not a median filter.\n",
    "    No mark if the implementation does not follow details given the lecture notes.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################        \n",
    "\n",
    "    # create the kernel array of filter as same size as filter_size\n",
    "    filter_array = [input_image[0][0]] * 9\n",
    "    \n",
    "    for j in range(1, H-1):\n",
    "        for i in range(1, W-1):\n",
    "            filter_array[0] = input_image[j-1, i-1]\n",
    "            filter_array[1] = input_image[j, i-1]\n",
    "            filter_array[2] = input_image[j+1, i-1]\n",
    "            filter_array[3] = input_image[j-1, i]\n",
    "            filter_array[4] = input_image[j, i]\n",
    "            filter_array[5] = input_image[j+1, i]\n",
    "            filter_array[6] = input_image[j-1, i+1]\n",
    "            filter_array[7] = input_image[j, i+1]\n",
    "            filter_array[8] = input_image[j+1, i+1]\n",
    "\n",
    "            # sort the array\n",
    "            filter_array.sort()\n",
    "\n",
    "            # put the median number into output array\n",
    "            new_image[j][i] = filter_array[4]\n",
    "\n",
    "    # This dummy code line can be removed after entering your code\n",
    "    #new_image = input_image.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KoFmQXCiBM-"
   },
   "source": [
    "---\n",
    "### Q6: Histogram equalization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1676484024914,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "62TsIS3TiBM-"
   },
   "outputs": [],
   "source": [
    "def my_histogram_equalization(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function performs histogram equalization on the input image.\n",
    "    The implementation of the histogram equalization follows the details given in the Image Enhancement lecture notes and tutorial.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input image array.\n",
    "\n",
    "    Return: new_image = histogram equalized image.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for estimating histogram, and histogram equalization cannot be used.\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the operation is not histogram equalization.\n",
    "    No mark if the implementation does not follow details given the lecture notes and tutorial.\n",
    "    No partial marking.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "    \n",
    "    \n",
    "    # convert our image into a numpy array\n",
    "    img = np.asarray(input_image)\n",
    "\n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = img.flatten()\n",
    "    \n",
    "    print(\"img: \",img.shape)\n",
    "    print(\"flat: \",flat.shape)\n",
    "\n",
    "    # show the histogram\n",
    "    plt.hist(flat, bins=50)\n",
    "    \n",
    "    def get_histogram(image, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram = np.zeros(bins)\n",
    "\n",
    "        # loop through pixels and sum up counts of pixels\n",
    "        for pixel in image:\n",
    "            histogram[pixel] += 1\n",
    "\n",
    "        # return our final result\n",
    "        return histogram\n",
    "\n",
    "    # execute our histogram function\n",
    "    hist = get_histogram(flat, 256)\n",
    "    \n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a):\n",
    "        a = iter(a)\n",
    "        b = [next(a)]\n",
    "        for i in a:\n",
    "            b.append(b[-1] + i)\n",
    "        return np.array(b)\n",
    "\n",
    "    # execute the fn\n",
    "    cs = cumsum(hist)\n",
    "    #print(\"cs\",cs)\n",
    "\n",
    "    # display the result\n",
    "    plt.plot(cs)\n",
    "    \n",
    "    \n",
    "    # numerator & denomenator\n",
    "    nj = (cs - cs.min()) * 255\n",
    "    N = cs.max() - cs.min()\n",
    "\n",
    "    # re-normalize the cumsum\n",
    "    cs = nj / N\n",
    "\n",
    "    # cast it back to uint8 since we can't use floating point values in images\n",
    "    cs = cs.astype('uint8')\n",
    "    \n",
    "    print(\"cs\",cs)\n",
    "\n",
    "    plt.plot(cs)\n",
    "    \n",
    "    img_new = cs[flat]\n",
    "    \n",
    "    # put array back into original shape since we flattened it\n",
    "    new_image = np.reshape(img_new, img.shape)\n",
    "\n",
    "\n",
    "    # This dummy code line can be removed after entering your code\n",
    "    #new_image = input_image.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5wGC8fTiBM_"
   },
   "source": [
    "---\n",
    "### Q7: Line and paper detection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1676484024915,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "j9Xu5F_NiBM_"
   },
   "outputs": [],
   "source": [
    "def my_line_detection(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function extracts two long sides of the major object, e.g., principal runway, by using the Hough transform.\n",
    "    It is assumed that in the image there is only one major object (principal runway) with clear boundary.\n",
    "    The object's long side is oriented along north direction approximately.\n",
    "    The implementation of the Hough transform follows the details given in the Line and Circle Detection lecture notes and tutorial.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input array representing an image.\n",
    "    This image has a major object with the long sides approximately parallel to the north direction.\n",
    "    The input image is corrupted by random noise.\n",
    "\n",
    "    Return: new_image = an original image with two white straight line segments (intensity = 255) outlining \n",
    "      the both long sides of the major object.\n",
    "    For each white straight line segment, it must be lying on the long side of the major object.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for Hough transform cannot be used.\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if the operation is not Hough transform.\n",
    "    No mark if the implementation does not follow details given the lecture notes and tutorial.\n",
    "    Partial marking is possible.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a new image which is identical to input image\n",
    "    H,W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    #[Your code goes here]\n",
    "    ############################\n",
    "    \n",
    "    new_image=input_image.copy()\n",
    "    threshold=195\n",
    "    brightness_threshold=99\n",
    "    edge_img=my_grad_mag(input_image)\n",
    "    edge_img[:,1]=0\n",
    "    edge_img[1,:]=0\n",
    "    edge_img[:,edge_img.shape[1]-2]=0\n",
    "    edge_img[edge_img.shape[0]-2,:]=0\n",
    "    #finding D using Pythagorean theorem\n",
    "    D = np.sqrt(edge_img.shape[0]**2+edge_img.shape[1]**2)\n",
    "    #since theta is from -90 to 90 ie range = 180\n",
    "    theta_min=-90\n",
    "    theta_max=90\n",
    "    theta_range = 180\n",
    "    rho_range = int(D)\n",
    "    accumulator = np.zeros((H*W*2 , theta_range))\n",
    "    bright_pixels = np.where(edge_img > np.percentile(edge_img.reshape(-1) , brightness_threshold))\n",
    "    coords = list(zip(bright_pixels[0], bright_pixels[1]))\n",
    "    for i in range(len(coords)):\n",
    "        for j in range(theta_min,theta_max+1):\n",
    "            rho = int(round(coords[i][1] * np.cos(np.deg2rad(j)) + coords[i][0] * np.sin(np.deg2rad(j))))\n",
    "            accumulator[rho + rho_range, j] += 1\n",
    "    rho , theta = np.where(accumulator >= threshold)\n",
    "    \n",
    "    #print('rho: ',rho, 'theta: ',theta)\n",
    "    \n",
    "    rhos=rho-rho_range\n",
    "    thetas=theta\n",
    "    lines=[]\n",
    "    for i in range(len(rhos)):\n",
    "        lines.append([rhos[i],thetas[i]])\n",
    "    lines=np.array(lines)\n",
    "    for r_theta in lines:\n",
    "        arr = np.array(r_theta, dtype=np.float64)\n",
    "        r,theta=arr\n",
    "        a = np.cos(np.deg2rad(theta))\n",
    "        b = np.sin(np.deg2rad(theta))\n",
    "        x0 = a*r\n",
    "        y0 = b*r\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        rr,cc=line(y1,x1,y2,x2)\n",
    "        rr=np.clip(rr,0,new_image.shape[0]-1)\n",
    "        cc=np.clip(cc,0,new_image.shape[1]-1)\n",
    "        new_image[rr,cc]=255\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################     \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1676484024916,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "VfOENRS92RWU"
   },
   "outputs": [],
   "source": [
    "def my_paper_detection(input_image):\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image_line = np.zeros((H, W))\n",
    "    new_image_rotate = np.zeros((H, W))\n",
    "    new_image_shear = np.zeros((H, W))\n",
    "    new_image_region = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "\n",
    "    new_image=input_image.copy()\n",
    "    pad=1\n",
    "    threshold=200\n",
    "    percentile=99.5\n",
    "    edge_img=my_grad_mag(input_image)\n",
    "    plt.imshow(edge_img, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    \n",
    "    #edge_img=(edge_img*edge_img.max())/255\n",
    "    #removing white borders\n",
    "    edge_img[:,1]=0\n",
    "    edge_img[1,:]=0\n",
    "    edge_img[:,edge_img.shape[1]-2]=0\n",
    "    edge_img[edge_img.shape[0]-2,:]=0\n",
    "    D = np.sqrt(edge_img.shape[0]*2 + edge_img.shape[1]*2)\n",
    "    #theta range -> 0 degree, 180 degree since origin is at the bottom left of the image        \n",
    "    #rho range -> 0, -diagonal length to +diagonal length        \n",
    "    theta_range = 180\n",
    "    rho_range = int(D)\n",
    "    #build accumulator        \n",
    "    accumulator = np.zeros((2*max(W,H) , theta_range))\n",
    "    # Threshold to get edges pixel location (x,y) - brightest percentile of pixels        \n",
    "    edge_pixels = np.where(edge_img > np.percentile(edge_img.reshape(-1) , percentile)) \n",
    "    coordinates = list(zip(edge_pixels[0], edge_pixels[1]))\n",
    "    print(len(coordinates))\n",
    "    # Calculate rho value for each edge location (x,y) with all the theta range        \n",
    "    for p in range(len(coordinates)):\n",
    "        for t in range(theta_range):\n",
    "            rho = int(round(coordinates[p][1] * np.cos(np.deg2rad(t)) + coordinates[p][0] * np.sin(np.deg2rad(t)))) # beware the flipping convention    \n",
    "            accumulator[rho + rho_range, t] += 1\n",
    "    rho , theta = np.where(accumulator >= threshold)\n",
    "    \n",
    "    #print(rho, theta)\n",
    "    rhos=rho-rho_range\n",
    "    thetas=theta\n",
    "    lines=[]\n",
    "    for i in range(len(rhos)):\n",
    "        lines.append([rhos[i],thetas[i]])\n",
    "    lines=np.array(lines)\n",
    "    #print(lines)\n",
    "    new_image_line = input_image.copy()\n",
    "    li=[]\n",
    "    \n",
    "    lines1=[]\n",
    "    if len(lines)>4:\n",
    "        for i in range(len(lines)-1):\n",
    "            if int(lines[i][0]+1) ==int(lines[i+1][0]) or int(lines[i][0]) ==int(lines[i+1][0]):\n",
    "                continue\n",
    "            else:\n",
    "                lines1.append(lines[i])\n",
    "\n",
    "            \n",
    "    lines1.append(lines[-1])\n",
    "    lines=lines1   \n",
    "    \n",
    "\n",
    "    for r_theta in lines:\n",
    "        #print(r_theta)\n",
    "        arr = np.array(r_theta, dtype=np.float64)\n",
    "        r,theta=arr\n",
    "        if r> max(H,W):\n",
    "            r=r%max(H,W)-max(H,W)\n",
    "        #print(arr)\n",
    "        #r=rho\n",
    "        #theta=1\n",
    "        #print(r)\n",
    "        #print(theta)\n",
    "        # Stores the value of cos(theta) in a\n",
    "        a = np.cos(np.deg2rad(theta))\n",
    "\n",
    "        # Stores the value of sin(theta) in b\n",
    "        b = np.sin(np.deg2rad(theta))\n",
    "\n",
    "        # x0 stores the value rcos(theta)\n",
    "        x0 = a*r\n",
    "\n",
    "        # y0 stores the value rsin(theta)\n",
    "        y0 = b*r\n",
    "\n",
    "        # x1 stores the rounded off value of (rcos(theta)-1000sin(theta))\n",
    "        x1 = int(x0 - 1000*(b))\n",
    "\n",
    "        # y1 stores the rounded off value of (rsin(theta)+1000cos(theta))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "\n",
    "        # x2 stores the rounded off value of (rcos(theta)+1000sin(theta))\n",
    "        x2 = int(x0 + 1000*(b))\n",
    "\n",
    "        # y2 stores the rounded off value of (rsin(theta)-1000cos(theta))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "\n",
    "\n",
    "        #print(x1,y1,x2,y2)\n",
    "        pts1=(y1,x1)\n",
    "        #print(pts1)\n",
    "        pts2=(y2,x2)\n",
    "        #print(pts2)\n",
    "        li.append((pts1,pts2))\n",
    "        \n",
    "        \n",
    "    def line_intersection(line1, line2):\n",
    "        xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "        ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "        def det(a, b):\n",
    "            return a[0] * b[1] - a[1] * b[0]\n",
    "        pts=[]\n",
    "        div = det(xdiff, ydiff)\n",
    "        if div == 0:\n",
    "            pass\n",
    "        d = (det(*line1), det(*line2))\n",
    "        try:\n",
    "            x = det(d, xdiff) / div\n",
    "            y = det(d, ydiff) / div\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        try:\n",
    "            if -input_image.shape[0]<x<input_image.shape[0] and -input_image.shape[1]<y<input_image.shape[1]:\n",
    "                pts.append((x,y))\n",
    "        except UnboundLocalError:\n",
    "            pass\n",
    "        return pts\n",
    "    \n",
    "    \n",
    "\n",
    "    points=[]\n",
    "    for i in range(len(li)):\n",
    "        for j in range(len(li)):\n",
    "            line1=li[i]\n",
    "            line2=li[j]\n",
    "            points.append(line_intersection(line1, line2))\n",
    "    new_image_line=input_image.copy()\n",
    "    \n",
    "    \n",
    "\n",
    "    point1=[]\n",
    "    for i in points:\n",
    "        if len(i)>0:\n",
    "            point1.append(i[0])\n",
    "\n",
    "    point1=list(set(point1))\n",
    "    #print(point1)\n",
    "    new_image_line=input_image.copy()\n",
    "    \n",
    "\n",
    "    top_left=sorted(point1)[0]\n",
    "    top_right=sorted(point1)[1]\n",
    "    bottom_left=sorted(point1)[2]\n",
    "    bottom_right=sorted(point1)[3]\n",
    "    \n",
    "    \n",
    "    print(\"top_left: \", top_left)\n",
    "    print('bottom_right: ', bottom_right)\n",
    "    print('top_right: ', top_right)\n",
    "    print('bottom_left: ', bottom_left)\n",
    "\n",
    "\n",
    "    #print( top_left, bottom_right, top_right, bottom_right)\n",
    "    rr,cc=line(int(top_left[0]),int(top_left[1]),int(top_right[0]),int(top_right[1]))\n",
    "    rr=np.clip(rr,0,input_image.shape[0]-1)\n",
    "    cc=np.clip(cc,0,input_image.shape[1]-1)\n",
    "    new_image_line[rr,cc]=255\n",
    "\n",
    "    rr,cc=line(int(bottom_left[0]),int(bottom_left[1]),int(bottom_right[0]),int(bottom_right[1]))\n",
    "    rr=np.clip(rr,0,input_image.shape[0]-1)\n",
    "    cc=np.clip(cc,0,input_image.shape[1]-1)\n",
    "    new_image_line[rr,cc]=255\n",
    "\n",
    "    rr,cc=line(int(top_left[0]),int(top_left[1]),int(bottom_left[0]),int(bottom_left[1]))\n",
    "    rr=np.clip(rr,0,input_image.shape[0]-1)\n",
    "    cc=np.clip(cc,0,input_image.shape[1]-1)\n",
    "    new_image_line[rr,cc]=255\n",
    "\n",
    "    rr,cc=line(int(top_right[0]),int(top_right[1]),int(bottom_right[0]),int(bottom_right[1]))\n",
    "    rr=np.clip(rr,0,input_image.shape[0]-1)\n",
    "    cc=np.clip(cc,0,input_image.shape[1]-1)\n",
    "    new_image_line[rr,cc]=255  \n",
    "\n",
    "    \n",
    "    plt.imshow(new_image_line)\n",
    "    \n",
    "    def image_rotate(image, degree, rot_point):\n",
    "            rads = np.deg2rad(degree)\n",
    "            rot_img = np.uint8(np.zeros(image.shape))\n",
    "            midx,midy = rot_point\n",
    "\n",
    "            for i in range(rot_img.shape[0]):\n",
    "                for j in range(rot_img.shape[1]):\n",
    "                    x= (i-midx)*np.cos(rads)+(j-midy)*np.sin(rads)\n",
    "                    y= -(i-midx)*np.sin(rads)+(j-midy)*np.cos(rads)\n",
    "\n",
    "                    x=round(x)+midx \n",
    "                    y=round(y)+midy \n",
    "\n",
    "                    if (x>=0 and y>=0 and x<image.shape[0] and  y<image.shape[1]):\n",
    "                        rot_img[i,j] = image[int(x),int(y)]\n",
    "\n",
    "            return rot_img\n",
    "    #print(bottom_left)\n",
    "    new_image_rotate=image_rotate(new_image_line, degree=20, rot_point=bottom_left)\n",
    "    plt.imshow(new_image_rotate)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    angle=77\n",
    "    factor=0.20\n",
    "    point=bottom_left\n",
    "    \n",
    "    def shear_image(image):\n",
    "        newimage = np.zeros((image.shape))\n",
    "        height, width = image.shape\n",
    "        y_mid = width / 2\n",
    "        x_mid = height / 2\n",
    "        newimage_x_mid, newimage_y_mid = x_mid, y_mid\n",
    "\n",
    "        for row in range(0,image.shape[0]):\n",
    "            for col in range(0,image.shape[1]):\n",
    "                y_prime = y_mid - col\n",
    "                x_prime = x_mid - row\n",
    "                \n",
    "                radian = np.deg2rad(angle)\n",
    "                tangent = 1 / np.tan(radian)\n",
    "                x_new = x_prime\n",
    "                y_new = round(y_prime + (x_prime * tangent))\n",
    "\n",
    "                xdist = int(newimage_x_mid - x_new)\n",
    "                ydist = int(newimage_y_mid - y_new)\n",
    "                if xdist < newimage.shape[0] and ydist < newimage.shape[1]:\n",
    "                    newimage[xdist, ydist] = image[row, col]\n",
    "\n",
    "        return newimage\n",
    "    \n",
    "    \n",
    "    def image_region(image):\n",
    "        newimage = np.zeros((image.shape))\n",
    "        height, width = image.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    new_image_shear = shear_image(new_image_rotate)\n",
    "    \n",
    "    plt.imshow(new_image_shear)\n",
    "    \n",
    "    #new_image_shear = new_image_rotate.copy()\n",
    "    new_image_region = new_image_shear.copy()\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image_line, new_image_rotate, new_image_shear, new_image_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QC3YC4EiBNA"
   },
   "source": [
    "---\n",
    "### Q8: Image segmentation by global thresholding\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1676484025239,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "8kX_jkzDiBNA"
   },
   "outputs": [],
   "source": [
    "def my_segmentation(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function performs image segmentation by global thresholding.\n",
    "    The segmentation results have three kinds of non-overlapping regions. \n",
    "    The segmentation results are represented by an image with three intensity levels, 10, 127 and 200. No pixel with other intensity levels.\n",
    "    10, 127 and 200 represent pixels originally with low-intensity, mid-intensity and high-intensity values, respectively.  \n",
    "    The global thresholds are estimated by using the Gaussian Mixture Model (GMM) and Expectation-Maximization (EM) method.\n",
    "    The number of Gaussian distributions is three.\n",
    "    The implementation of GMM and EM method follows the details given in the lecture notes and the tutorial.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "\n",
    "    Parameter: input_image = input array representing an image.\n",
    "    \n",
    "    Return:\n",
    "    new_image = a segmented image with three kinds of non-overlapping regions. \n",
    "    Each region is represented by an intensity level.\n",
    "    There are three intensity levels, 10, 127 and 200.\n",
    "    Regions with intensity level 10 are pixels originally with low-intensity values.\n",
    "    Regions with intensity level 127 are pixels originally with mid-intensity values.\n",
    "    Regions with intensity level 200 are pixels originally with high-intensity values.\n",
    "    \n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for estimating histogram, GMM and EM method cannot be used.\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output image will be marked.\n",
    "    No mark if any global threshold is hard coded. \n",
    "    No mark if the global thresholds are not estimated by using EM method and GMM. \n",
    "    No mark if the operation is not using EM method.\n",
    "    No mark if the operation is not using GMM.\n",
    "    No mark if the implementation does not follow details given the lecture notes and tutorial.\n",
    "    Partial marking is possible.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "    new_image = input_image.copy()\n",
    "    labels = np.zeros((H, W), dtype=np.uint8)\n",
    "    labels[input_image < 100] = 1\n",
    "    labels[(input_image >= 100) & (input_image < 200)] = 2\n",
    "    labels[input_image >= 200] = 3\n",
    "    mu = np.array([50, 120, 200])\n",
    "    var = np.array([15, 15, 15])\n",
    "    w = np.array([1/3, 1/3, 1/3])\n",
    "    \n",
    "    for i in range(100):\n",
    "        p = np.zeros((H, W, 3))\n",
    "        for k in range(3):\n",
    "            p[:, :, k] = w[k] * np.exp(-0.5 * (input_image - mu[k])**2 / var[k]) / np.sqrt(2 * np.pi * var[k])\n",
    "        p_sum = np.sum(p, axis=2)\n",
    "        p_sum[p_sum == 0] = 1\n",
    "        p /= p_sum[:, :, np.newaxis]\n",
    "        N = np.sum(p, axis=(0, 1))\n",
    "        w = N / (H * W)\n",
    "        mu = np.sum(p * input_image[:, :, np.newaxis], axis=(0, 1)) / N\n",
    "        var = np.sum(p * (input_image[:, :, np.newaxis] - mu)**2, axis=(0, 1)) / N\n",
    "        if np.allclose(mu, np.mean(input_image)):\n",
    "            break\n",
    "        sorted_mus = np.sort(mu)\n",
    "        t1 = (sorted_mus[0]+sorted_mus[1])/2\n",
    "        t2 = (sorted_mus[2]+sorted_mus[1])/2\n",
    "        new_image[input_image <= t1] = 10\n",
    "        new_image[(input_image > t1) & (input_image <= t2)] = 127\n",
    "        new_image[input_image > t2] = 200\n",
    "            \n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLojPuBniBNA"
   },
   "source": [
    "---\n",
    "### Q9: Circle detection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676484025240,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "VjKEmxZRiBNA"
   },
   "outputs": [],
   "source": [
    "def my_circle_detection(input_image):\n",
    "    \"\"\"Description:\n",
    "    This function extracts the round objects (including missing parts) in an image by using the Hough transform method.\n",
    "    The number of round objects in the image is at least one.\n",
    "    If more than one object, their intensity values may be different. The objects may touch. \n",
    "    The implementation follows the details given in the Line and Circle Detection lecture notes and the tutorial.\n",
    "    Intensity values outside the image region are assumed zero.\n",
    "    You can assume the round object diameter ranges from 188 pixels to 196 pixels.\n",
    "\n",
    "    Parameter: input_image = input array representing an image.\n",
    "    This image has at least one round object. Some round objects have missing parts.\n",
    "    The image has been corrupted by random noise.\n",
    "\n",
    "    Return: \n",
    "    new_image_circles = an original image with the round objects overlaid with the white detected circle(s) (intensity = 255).\n",
    "    new_image_largest = an image shows the largest round object with its white detected circle. \n",
    "      Regions outside the white detected circle are removed (set to zero intensity value), and inside circle remain unchanged.\n",
    "    new_image_sorted = an image shows all round objects (with their white detected circles) aligning horizontally in the middle of the image.\n",
    "      The detected circles containing round objects are displaced to achieve horizontal alignment.\n",
    "      The left-most circle contains the largest object and the right-most circle contains the smallest object.\n",
    "      Regions outside the white detected circles are removed (set to zero intensity value), and inside circles remain unchanged.\n",
    "\n",
    "    Requirements:\n",
    "    Pre-defined functions for Hough transform cannot be used.\n",
    "    Pre-defined functions for filtering, convolution, correlation cannot be used, e.g., filter2D.\n",
    "    You must use double for-loop (nested for-loop) for accessing pixels in the input image.\n",
    "\n",
    "    Marking criteria:\n",
    "    The output images will be marked.\n",
    "    No mark if the operation is not Hough transform.\n",
    "    No mark if the implementation does not follow details given the lecture notes and tutorial.\n",
    "    Mark deduction if image aliasing is observed.\n",
    "    Partial marking is possible.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new image which is identical to input image\n",
    "    H, W = input_image.shape\n",
    "    new_image_circles = np.zeros((H, W))\n",
    "    new_image_largest = np.zeros((H, W))\n",
    "    new_image_sorted = np.zeros((H, W))\n",
    "\n",
    "    ############################\n",
    "    # [Your code goes here]\n",
    "    ############################\n",
    "\n",
    "    # This dummy code block can be removed after entering your code\n",
    "    new_image_circles = input_image.copy()\n",
    "    new_image_largest = input_image.copy()\n",
    "    new_image_sorted = input_image.copy()\n",
    "    rr, cc, val = circle_perimeter_aa(300, 300, 100)\n",
    "    new_image_circles[rr, cc] = 255.0\n",
    "    new_image_largest[rr, cc] = 255.0\n",
    "    new_image_sorted[rr, cc] =255.0\n",
    "\n",
    "    ############################\n",
    "    # [Your code ends here]\n",
    "    ############################\n",
    "\n",
    "    return new_image_circles, new_image_largest, new_image_sorted\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bc22xm7iBNB"
   },
   "source": [
    "---\n",
    "## Output Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676484025241,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "-AdVtVpeiBNB"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"The main function for this coursework.\n",
    "\n",
    "    Parameter: none.\n",
    "\n",
    "    Return: none.\n",
    "    \"\"\"\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q1: Image negative (2 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig0304(a)(breast_digital_Xray).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for image negative')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_image_negative.jpg', my_image_negative(input_image))\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q2: Image smoothing (4 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig0333(a)(test_pattern_blurring_orig).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for image smoothing')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_image_smoothing.jpg', my_image_smoothing(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q3: Edge gradient magnitude estimation (4 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig1026(a)(headCT-Vandy).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for gradient magnitude estimation')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_grad_mag.jpg', my_grad_mag(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q4: Image sharpening (4 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig0343(a)(skeleton_orig).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for image sharpening')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_image_sharpening.jpg', my_image_sharpening(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q5: Image median filtering (4 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig0335(a)(ckt_board_saltpep_prob_pt05).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for median filtering')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_median_filtering.jpg', my_median_filtering(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q6: Histogram equalization (8 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig0320(4)(bottom_left).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for histogram equalization')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_histogram_equalization.jpg', my_histogram_equalization(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q7: Line and paper detection (38 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig1034(a)(marion_airport).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for line detection')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_line_detection.jpg', my_line_detection(input_image))\n",
    "\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    input_image = plt.imread('FigPaper.tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for paper detection')\n",
    "    plt.show()\n",
    "\n",
    "    # output image files\n",
    "    new_image_line, new_image_rotate, new_image_shear, new_image_region = my_paper_detection(input_image)\n",
    "    output_image('output_paper_detection_line.jpg', new_image_line)\n",
    "    output_image('output_paper_detection_rotate.jpg', new_image_rotate)\n",
    "    output_image('output_paper_detection_shear.jpg', new_image_shear)\n",
    "    output_image('output_paper_detection_region.jpg', new_image_region)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q8: Image segmentation by global thresholding (12 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    # The image is obtained from ImageProcessingPlace.com, DIP3/e\n",
    "    input_image = plt.imread('Fig1045(a)(iceberg).tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for image segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    # output image file\n",
    "    output_image('output_segmentation.jpg', my_segmentation(input_image))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Q9: Circle detection (24 marks)\n",
    "    ###############################################################################\n",
    "    # read in a 2D image for testing, input_image is a 2D ndarray\n",
    "    input_image = plt.imread('FigCircles.tif')\n",
    "    plt.imshow(input_image, vmin=0, vmax=255, cmap=plt.cm.gray)\n",
    "    plt.title(f'Input image for circle detection')\n",
    "    plt.show()\n",
    "\n",
    "    # output image files\n",
    "    new_image_circles, new_image_largest, new_image_sorted = my_circle_detection(input_image)\n",
    "    output_image('output_circle_detection_all.jpg', new_image_circles)\n",
    "    output_image('output_circle_detection_largest.jpg', new_image_largest)\n",
    "    output_image('output_circle_detection_sorted.jpg', new_image_sorted)\n",
    "    \n",
    "\n",
    "\n",
    "def output_image(filename, image_array):\n",
    "    \"\"\"This function outputs image_array into an image file in jpg format.\n",
    "\n",
    "    Parameters:\n",
    "    filename = file name of the output image file.\n",
    "    image_array = input 2D numpy array. uint8 type with range [0-255] per pixel.\n",
    "\n",
    "    Return: none.\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = image_array.shape\n",
    "    output_image_rgb = np.zeros((H, W, 3))  # type = numpy.float64\n",
    "    output_image_rgb[:, :, 0] = image_array\n",
    "    output_image_rgb[:, :, 1] = image_array\n",
    "    output_image_rgb[:, :, 2] = image_array\n",
    "    plt.imsave(filename, output_image_rgb.astype(np.uint8))  # convert type to uint8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4414,
     "status": "ok",
     "timestamp": 1676484029649,
     "user": {
      "displayName": "Albert C.S. Chung",
      "userId": "01636718548544693254"
     },
     "user_tz": 0
    },
    "id": "h4szbe3GiBNC",
    "outputId": "48731f6e-3d05-43e0-b1c9-cfd24fafdbad"
   },
   "outputs": [],
   "source": [
    "# Run this code block to see your output images\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
